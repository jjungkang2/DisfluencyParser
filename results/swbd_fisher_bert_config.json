{
  "attention_dropout": 0.2,
  "batch_size": 30,
  "bert_do_lower_case": true,
  "bert_model": "bert-base-uncased",
  "char_lstm_input_dropout": 0.2,
  "checks_per_epoch": 4,
  "clip_grad_norm": 0,
  "d_char_emb": 32,
  "d_ff": 2048,
  "d_kv": 64,
  "d_label_hidden": 250,
  "d_model": 1024,
  "d_tag_hidden": 250,
  "default_label_weight": 0.69,
  "embedding_dropout": 0.0,
  "epoch10_hurdle": 0.0,
  "epoch1_hurdle": 0.0,
  "epochs": 100,
  "eval_batch_size": 16,
  "evalb_dir": "EVALB/",
  "learning_rate": 0.00005,
  "learning_rate_warmup_steps": 160,
  "max_len_dev": 0,
  "max_len_train": 0,
  "model_path_base": "results/swbd_fisher_bert_Edev",
  "morpho_emb_dropout": 0.2,
  "num_heads": 8,
  "num_layers": 2,
  "num_layers_position_only": 0,
  "partitioned": true,
  "predict_tags": false,
  "print_minibatches": false,
  "print_vocabs": false,
  "relu_dropout": 0.1,
  "residual_dropout": 0.2,
  "sentence_max_len": 300,
  "special_label_weight": 2.05,
  "silver_weight": 4,
  "step_decay": true,
  "step_decay_factor": 0.5,
  "step_decay_patience": 5,
  "subbatch_max_tokens": 500,
  "tag_emb_dropout": 0.2,
  "tag_loss_scale": 5.0,
  "timing_dropout": 0.0,
  "use_bert": true,
  "use_chars_concat": false,
  "use_tags": false,
  "use_words": false,
  "word_emb_dropout": 0.4
}
